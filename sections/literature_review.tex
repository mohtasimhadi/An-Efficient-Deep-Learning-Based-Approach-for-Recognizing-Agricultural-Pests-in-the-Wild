Many researchers have used deep learning algorithms in agriculture in recent years. GoogleNet, AlexNet, ResNet, and other deep convolutional neural networks perform admirably well for image classification tasks. The majority of the applications, however, are focused on weed identification \cite{dyrmann2016plant} plant recognition \cite{reyes2015fine, zhang2018deep}, fruit counting \cite{chen2017counting}, and crop type \cite{zhang2018deep} classification.
\subsection{Subdomains in agriculture}
Research in agriculture is important because it helps to improve the efficiency, productivity, and sustainability of agricultural practices. By studying the best ways to grow crops, raise livestock and fisheries, and manage pests and diseases, researchers can help to increase crop yields, reduce the need for chemical inputs, and protect the environment. The agriculture field is very vast there are a number of domains to work on here. Kamilaris and Prenafeta-Boldu \cite{14_kamilaris2018deep} and Saleem et al \cite{15_saleem2019plant} have identified the subdomains of the agriculture domain as follows- 
\begin{itemize}
    \item Plant leaf disease detection, segmentation and diagnosis
    \item Plant disease detection and diagnosis
    \item Crop pest detection
    \item Crop analysis with aerial image
    \item Crop weed detection
    \item Crop yield (harvest) prediction
    \item Crop classification
    \item Crop growth monitoring
\end{itemize}
\subsection{Use of deep learning and it's influencing factors}
Different machine learning techniques name as Regression, Clustering, Bayessian Models, Instance Based Models, Decision Trees, SVM, KNN etc are being used already in this domain \cite{16_liakos2018machine}. These techniques had put some impact results in the research of agriculture system automation but the real evolution came when deep learning architecture took the place. Now networks can be more deeper and a lot of resources can be used to feed the networks. That shows tremendous advancement in the field of computer vision based agricultural research. Researchers now using different deep learning networks like CNN, GoogleNet, Resnet, VGG , Inception etc \cite{14_kamilaris2018deep}. As agriculutre based sectors are based on mostly image and video clips. Deep learning techniques has a large impact on this. After studying some survey papers we narrowed down the field by selecting two sub sectors which seemed to have more potential. The fields are plants' disease detection, segmentation \& diagnosis and crop pest classification. First we conducted studies on plant disease detection. There are some factors which influences highly for deep learning based plant disease recognition\cite{17_barbedo2018factors}-
\begin{itemize}
    \item \textbf{Limited annoted dataset:} There are not enough qualityfull dataset in this agriculture field. Making a good dataset in this field not so easy. First of all, enough sample should be ensured to feed the deep learning networks. Secondly data annotation should be done carefully because it is very difficult for an ordinary person to identify different disease or crops of agriculture field. Moreover these disease or crops may be at the different growth stage of the life.
    
    \item \textbf{System representation:} There are a lot of types and varieties are available in this field. There are different species and classes for a single plant. Moreover a same plant may look different based on different conditions and environments. Without this there may be a similar disease or pest which can affect multiple plant species. So a good representation of these info in the dataset is very important which is a rare case.
    
    \item \textbf{Covariate shift:} At the time of training and evaluating a method on the same dataset, the model's performance is often overstated because it will fail when implemented to other datasets. As previously stated, datasets are not robust, and even the same plant can appear differently in different locations, so models frequently fail to perform well for images other than their own testing and training datasets.

    \item \textbf{Image background:} Complex background is a big problem in this sector. For example a single disease may effect different plant but the color, size in the background can be different. Moreover there will be soil , grass, different plants hands etc present in the picture. Often the focused object like disease zone or pest can be differ in size. There are also huge possibility of color similarity between the focused objects and the background. The focused leaf or crop can be damged differently also for different which can cause change in the background.
    \item \textbf{Image capture condition:} Images captured in most of the datasets differ from one to another depending on the condition of the day, light time, camera positioning, environment and so many. Due to the reason, region of interest looks different from one image to another in the same class or even same insect of the same dataset.
    \item \textbf{Symptom segmentation:} The fact that it is not essential to precisely identify the indicators in the image is one of the key benefits of employing deep learning methods.The issue of symptom segmentation is not pertinent in this situation, despite the fact that it may be useful to isolate the area where the symptom is present because it often contains the majority of the crucial information. The results were not significantly changed by expanding the sample size or by limiting the study area to the site of the symptoms. Furthermore, by concentrating on specific nodules, it is feasible to integrate the predicted classes to develop a comprehensive diagnostic for the plant, which might lessen the impact of individual misclassifications. 
    \item \textbf{Symptom variations:} While the majority of diseases have recognizable visual symptoms, these symptoms frequently vary in appearance, especially in terms of color, shape, and size. Due to this unpredictability, it may be difficult to employ visible-spectrum-based image-based diagnostics to discriminate between healthy and unhealthy pixels.   \cite{17_barbedo2018factors}. As symptoms can range from being extremely faint and barely perceptible in the early stages of infection to causing extensive tissue death in the most advanced stages, the stage of the disease (or the intensity of the symptoms) is probably the most significant source of heterogeneity. This means that differentiating various diseases may be simpler or more difficult depending on the stage of infection. 
    \item \textbf{Simultaneous disorders:} Images typically have an illness tagged next to them. However, it is typical for several illnesses or other types of issues, like nutrient deficits or pests, to exist concurrently. This is frequently true because weakened by one virus, a plant's immune system can make it more vulnerable to other diseases. Creating mixed classes with all conceivable combinations of disorders could be one solution to this problem. This strategy is not realistic, though, as there would be an excessive number of classifications, which would raise the possibility of misclassification. Additionally, the inter-variability would be too high because the percentage of symptoms linked to each disease can differ from one image to the next. 
    \item \textbf{Disorders with similar symptom:} One host species may have lesions and other symptoms from a variety of agents, such as illnesses, nutritional deficits, pests, and mechanical harm. Even plant pathologists have faced trouble sometimes for differentiating between some of these chemicals since their symptoms can be so similar.
As a result, visual cues alone might not be adequate to correctly categorize some issues.
Even if an image is very clearly caught, a specific diagnosis could be impossible because of the symptoms' broad nature.
Human experts frequently take into account additional facts to make accurate decisions, such as the current weather condition, historical illness data and stats, and the overall health of the plant.
The accuracy of disease recognition algorithms may be increased by including this kind of additional data.  \cite{14_kamilaris2018deep}.
\end{itemize}
\subsection{Existing works}
Mohanty et al. \cite{mohanty2016using} trained AlexNet and GoogleNet using PlantVillage dataset which contains 54,306 images with 14 crop species and 26 kinds of diseases (only lab environment image) via transfer learning. A novel CNN-Fourier Dense Network was proposed and evaluated by Lin et al. \cite{lin2019fourier} with their self-built dataset based on the optical images captured using an unmanned aerial vehicle.

Wang et al. \cite{wang2017crop} applied AlexNet and LeNet deep networks and achieved a classification accuracy of 91\%. They used their self-made dataset containing 30,000 pest images in 82 classes and also analyzed the kernels effect in the cnn layers and cnn layers number on the classification performance.

Wu et al. \cite{wu2019ip102} collected image data from different sources like internet, newspaper, magazine etc and created a large dataset of insect pests which contains more than 75,000 field images belonging 102 categories of crops where about 19,000 box annotated images for object detection. The dataset is evaluated on some classical machine learning techniques and also modern deep learning-based techniques. Later many used the database to evaluate their own approaches. Such includes Ren et al. \cite{ren2019feature}. They came up with a new feature reuse residual block (FR-ResNet) structure which is based on classic residual blocks which can help to improve the capacity of data representation. With their proposed technique they achieved an accuracy of 55.24\% using FR-ResNet whereas the state of the art ResNet-50 method brings 54.19\% accuracy. Liu et al. \cite{liu2016localization} also proposed a new residual-based block network architetcure named multi-branch fusion residual network (DMF-ResNet) for multi-scale representations. In the proposed method conventional residual network is combined with bottleneck residual network architecture into the residual model with multiple branches. They measured the performance with other sota methods and the experiment came up with an enhancement in the result.

Nanni et al. \cite{nanni2020insect} also used IP102 and another small dataset for their proposed ensemble strategy which combines saliency methods and CNNs. They augmented the data using different saliency methods and able to achieve an accuracy of 91\% in their small dataset. But the accuracy in IP102 was 61.93\%. Ayan et al. \cite{ayan2020crop} proposed a genetic algorithm based weighted ensemble of deep convolutional neural networks. They used D0, a small dataset with 40 classes and IP102 to evaluate their performance and achieved 98.19\% for the D0 dataset, 95.15\% for a dataset created by taking 10 classes of IP102 and 67.13\% in IP102. Both of the approaches are enhanced compared to the sota methods of classifications but full ip102 dataset is not taken.